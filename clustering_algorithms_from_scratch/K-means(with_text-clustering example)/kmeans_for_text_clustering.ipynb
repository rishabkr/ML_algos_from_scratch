{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Kmeans Clustering on Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import spatial\n",
    "import os\n",
    "from collections import Counter\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below calculates distance between two data points.Tried for various distanca metrics like cosine distance,sine distance,eucledian distance,but only eucledian gave proper results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(p1,p2):\n",
    "    #print(1 - spatial.distance.cosine(p1,p2))\n",
    "    #return 1 - spatial.distance.cosine(p1,p2)\n",
    "    return np.sqrt(np.sum((p1-p2)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds the nearest centroid that point belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_centroid(sample,centroids):\n",
    "    distances=[]\n",
    "    for point in centroids:\n",
    "        d=distance(sample,point)\n",
    "        distances.append(d)\n",
    "    closest=np.argmin(distances)\n",
    "    return closest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates clusters/assigns points to clusters.Populates clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clusters(X_train,K,centroids):\n",
    "    clusters=[[] for _ in range(K)]\n",
    "    for index,sample in enumerate(X_train):\n",
    "        centroid_index=closest_centroid(sample,centroids)\n",
    "        clusters[centroid_index].append(index)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds centroids of the current collection of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids(clusters,K,num_features,X_train):\n",
    "    centroids=np.zeros((K,num_features))\n",
    "    for cluster_index,cluster in enumerate(clusters):\n",
    "        cluster_mean=np.mean(X_train[cluster],axis=0)\n",
    "        centroids[cluster_index]=cluster_mean\n",
    "    return centroids    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(K,X_train,num_iterations,plot_steps=False):\n",
    "    clusters=[[] for _ in range(K)]\n",
    "    centroids=[]\n",
    "    num_samples=X_train.shape[0]\n",
    "    num_features=X_train.shape[1]\n",
    "    cnt=0\n",
    "    #initializing centroids between 0 and number of samples\n",
    "    random_indexes=np.random.choice(num_samples,K,replace=False)\n",
    "    #random_indexes=[ 191 , 183  , 84  ,797 ,1695]\n",
    "    #random_indexes=kmeanspp(X_train,K)\n",
    "    #191  183   84  797 1695\n",
    "    #[ 795  651 1091  782 1065]\n",
    "    #1386,91,1061,1144,444\n",
    "    centroids=[X_train[index] for index in random_indexes]\n",
    "    print(random_indexes)\n",
    "    while(cnt<=num_iterations):\n",
    "        cnt+=1\n",
    "        clusters=create_clusters(X_train,K,centroids)\n",
    "        centroids_old=centroids\n",
    "        centroids=get_centroids(clusters,K,num_features,X_train)\n",
    "        #centroids=kmeanspp(X_train,K)\n",
    "        #if(cnt%10==0):    \n",
    "            #print(cnt)\n",
    "        completed=[]\n",
    "        for i in range(K):\n",
    "            d=distance(centroids_old[i],centroids[i])\n",
    "            completed.append(d)\n",
    "        if(sum(completed)==0):\n",
    "            break\n",
    "    #return get_cluster_labels(clusters,num_samples)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanpunc(sentence):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in sentence if ch not in exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1725"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names=os.listdir(r'C:\\Users\\Rishab\\Assignment-2_Dataset\\Datasets\\Question-6\\dataset')\n",
    "len(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data={'files':list(), 'data':list()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in file_names:\n",
    "    with open(r'C:\\Users\\Rishab\\Assignment-2_Dataset\\Datasets\\Question-6\\dataset\\\\'+filename,\"r\") as data:\n",
    "        if filename in text_data:\n",
    "            continue\n",
    "        text_data['files'].append(filename)\n",
    "        text_data['data'].append(data.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "for name in file_names:\n",
    "    label=name.split('_')\n",
    "    label=label[1].split('.')\n",
    "    labels.append(label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data['labels']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "      <th>data</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100_1.txt</td>\n",
       "      <td>Shares rise on new Man Utd offer\\n\\nShares in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100_2.txt</td>\n",
       "      <td>Slater to star in Broadway play\\n\\nActor Chris...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100_3.txt</td>\n",
       "      <td>Galloway plea for hostage release\\n\\nEx-Labour...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100_4.txt</td>\n",
       "      <td>Connors boost for British tennis\\n\\nFormer wor...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100_5.txt</td>\n",
       "      <td>Moving mobile improves golf swing\\n\\nA mobile ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       files                                               data labels\n",
       "0  100_1.txt  Shares rise on new Man Utd offer\\n\\nShares in ...      1\n",
       "1  100_2.txt  Slater to star in Broadway play\\n\\nActor Chris...      2\n",
       "2  100_3.txt  Galloway plea for hostage release\\n\\nEx-Labour...      3\n",
       "3  100_4.txt  Connors boost for British tennis\\n\\nFormer wor...      4\n",
       "4  100_5.txt  Moving mobile improves golf swing\\n\\nA mobile ...      5"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(text_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions will be used in preprocessing the text,the functions will be taking input as texts and will remove the punctuations,and change all of them to lower case for uniformness.The data henced process will be used for further stages of classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "i=0\n",
    "list_of_sentences=[]\n",
    "for sent in df['data'].values:\n",
    "    filtered_sentence=[]\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sentences.append(filtered_sentence)\n",
    "    \n",
    "    df.loc[i,'filtered_data']=' '.join(filtered_sentence)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "      <th>data</th>\n",
       "      <th>labels</th>\n",
       "      <th>filtered_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100_1.txt</td>\n",
       "      <td>Shares rise on new Man Utd offer\\n\\nShares in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>shares rise on new man utd offer shares in man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100_2.txt</td>\n",
       "      <td>Slater to star in Broadway play\\n\\nActor Chris...</td>\n",
       "      <td>2</td>\n",
       "      <td>slater to star in broadway play actor christia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100_3.txt</td>\n",
       "      <td>Galloway plea for hostage release\\n\\nEx-Labour...</td>\n",
       "      <td>3</td>\n",
       "      <td>galloway plea for hostage release exlabour mp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100_4.txt</td>\n",
       "      <td>Connors boost for British tennis\\n\\nFormer wor...</td>\n",
       "      <td>4</td>\n",
       "      <td>connors boost for british tennis former world ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100_5.txt</td>\n",
       "      <td>Moving mobile improves golf swing\\n\\nA mobile ...</td>\n",
       "      <td>5</td>\n",
       "      <td>moving mobile improves golf swing a mobile pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>9_1.txt</td>\n",
       "      <td>Saudi investor picks up the Savoy\\n\\nLondon's ...</td>\n",
       "      <td>1</td>\n",
       "      <td>saudi investor picks up the savoy londons famo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>9_2.txt</td>\n",
       "      <td>Surprise win for anti-Bush film\\n\\nMichael Moo...</td>\n",
       "      <td>2</td>\n",
       "      <td>surprise win for antibush film michael moores ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>9_3.txt</td>\n",
       "      <td>Correction agency plans dropped\\n\\nPlans to cr...</td>\n",
       "      <td>3</td>\n",
       "      <td>correction agency plans dropped plans to creat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>9_4.txt</td>\n",
       "      <td>Cole refuses to blame van Persie\\n\\nAshley Col...</td>\n",
       "      <td>4</td>\n",
       "      <td>cole refuses to blame van persie ashley cole h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>9_5.txt</td>\n",
       "      <td>Open source leaders slam patents\\n\\nThe war of...</td>\n",
       "      <td>5</td>\n",
       "      <td>open source leaders slam patents the war of wo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1725 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          files                                               data labels  \\\n",
       "0     100_1.txt  Shares rise on new Man Utd offer\\n\\nShares in ...      1   \n",
       "1     100_2.txt  Slater to star in Broadway play\\n\\nActor Chris...      2   \n",
       "2     100_3.txt  Galloway plea for hostage release\\n\\nEx-Labour...      3   \n",
       "3     100_4.txt  Connors boost for British tennis\\n\\nFormer wor...      4   \n",
       "4     100_5.txt  Moving mobile improves golf swing\\n\\nA mobile ...      5   \n",
       "...         ...                                                ...    ...   \n",
       "1720    9_1.txt  Saudi investor picks up the Savoy\\n\\nLondon's ...      1   \n",
       "1721    9_2.txt  Surprise win for anti-Bush film\\n\\nMichael Moo...      2   \n",
       "1722    9_3.txt  Correction agency plans dropped\\n\\nPlans to cr...      3   \n",
       "1723    9_4.txt  Cole refuses to blame van Persie\\n\\nAshley Col...      4   \n",
       "1724    9_5.txt  Open source leaders slam patents\\n\\nThe war of...      5   \n",
       "\n",
       "                                          filtered_data  \n",
       "0     shares rise on new man utd offer shares in man...  \n",
       "1     slater to star in broadway play actor christia...  \n",
       "2     galloway plea for hostage release exlabour mp ...  \n",
       "3     connors boost for british tennis former world ...  \n",
       "4     moving mobile improves golf swing a mobile pho...  \n",
       "...                                                 ...  \n",
       "1720  saudi investor picks up the savoy londons famo...  \n",
       "1721  surprise win for antibush film michael moores ...  \n",
       "1722  correction agency plans dropped plans to creat...  \n",
       "1723  cole refuses to blame van persie ashley cole h...  \n",
       "1724  open source leaders slam patents the war of wo...  \n",
       "\n",
       "[1725 rows x 4 columns]"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=df['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shares rise on new man utd offer shares in manchester united closed up on monday following a new offer from us tycoon malcolm glazer the board of the football club is expected to meet early this week to discuss the latest proposal which values the club at manchester united revealed on sunday that it had received a detailed proposal from mr glazer which looks set to receive more serious scrutiny the club has previously rejected mr glazers approaches out of hand but a senior source at the club told the bbc this time its different supporters group shareholders united however urged the club to reject the new deal a spokesman for the shareholders united said i cant see any difference compared to mr glazers previous proposals other than less debt he isnt bringing any money into the club hell use our money to buy it mr glazers latest move is being led by mr glazers two sons avi and joel according to the financial times a proposal was received by david gill uniteds chief executive at the end of last week pitched at about a share david cummings head of uk equities for standard life investments said he believed a well funded a share bid would be enough for mr glazer to take control of the club i do not think there is anything that manchester united fans can do about it he told the bbc they can complain about it but it is curtains for them they may not want him but they are going to get him the us tycoon who has been wooing the club for the last months has approached the united board with detailed proposals it has confirmed mr glazer who owns the tampa bay buccaneers team hopes this will lead to a formal bid being accepted he is believed to have increased the amount of equity in the new proposal though it is not clear by how much for his proposal to succeed he needs the support of uniteds largest shareholders the irish horseracing tycoons jp mcmanus and john magnier they own of united through their cubic expression investment vehicle mr glazer and his family hold a stake of but it is not yet known whether mr mcmanus and mr magnier would support a glazer bid nm rothschild the investment bank is advising mr glazer according to the financial times his previous adviser jpmorgan quit last year when mr glazer went ahead and voted against the appointment of three united directors to the board against its advice but the ft said it thought jp morgan may still have had some role in financing mr glazers latest financial proposal'"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['filtered_data'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "Tfidf_vect = TfidfVectorizer(stop_words='english')\n",
    "Train_X_Tfidf=Tfidf_vect.fit_transform(df['filtered_data'])\n",
    "Train_X_Tfidf=np.array(Train_X_Tfidf.todense())\n",
    "#print(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1725, 28020)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X_Tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy array now has more dimensions than csr representation,but it is how my model was built.It only handles numpy array as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X_Tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a well known fact that Kmeans clustering is sensitive to initalization.\n",
    "The initial clusters chosen tremendously effects the cluster formation/detection.\n",
    "Hence while experimenting one of the settings i.e 191  183   84  797 1695 showed the best accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best clustering accuracy was found when the initial centroids were chosen as [191  183   84  797 1695] indices.\n",
    "It showed 91.2 % accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[191, 183, 84, 797, 1695]\n",
      "0.912463768115942\n"
     ]
    }
   ],
   "source": [
    "num_clusters =5\n",
    "for _ in range(1):\n",
    "    clusters=predict(num_clusters,Train_X_Tfidf,200,plot_steps=False)\n",
    "    klst=[1,2,3,4,5]\n",
    "    cluster_labels=[]\n",
    "    for k in klst:\n",
    "        ans = Counter(actual[clusters[k-1]]).most_common()\n",
    "        cluster_labels.append(ans[0][0])\n",
    "    final_labels=[0 for _ in range(len(actual))]\n",
    "    for i in range(len(clusters)):\n",
    "        for j in clusters[i]:\n",
    "            final_labels[j] = cluster_labels[i]\n",
    "    print(np.sum(final_labels==actual)/len(actual))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following run is when clusters are initialized randomly and hence we see varying accuracy results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 126  717 1366  491  819]\n",
      "0.6272463768115942\n",
      "[ 900  408 1202  192  366]\n",
      "0.823768115942029\n",
      "[1608  369 1124 1150 1299]\n",
      "0.758840579710145\n",
      "[1558  552  315  594 1595]\n",
      "0.7547826086956522\n",
      "[ 308  165 1225 1137 1128]\n",
      "0.5814492753623188\n"
     ]
    }
   ],
   "source": [
    "num_clusters =5\n",
    "for _ in range(5):\n",
    "    clusters=predict(num_clusters,Train_X_Tfidf,200,plot_steps=False)\n",
    "    klst=[1,2,3,4,5]\n",
    "    cluster_labels=[]\n",
    "    for k in klst:\n",
    "        ans = Counter(actual[clusters[k-1]]).most_common()\n",
    "        cluster_labels.append(ans[0][0])\n",
    "    final_labels=[0 for _ in range(len(actual))]\n",
    "    for i in range(len(clusters)):\n",
    "        for j in clusters[i]:\n",
    "            final_labels[j] = cluster_labels[i]\n",
    "    print(np.sum(final_labels==actual)/len(actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
